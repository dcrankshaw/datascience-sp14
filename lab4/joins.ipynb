{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Joining DataFrames in Pandas\n",
      "\n",
      "In previous labs, we've explored the power tables as a data management abstraction, in particular with the Pandas DataFrame object.\n",
      "Tables let us select rows and columns of interest, group data, and measure aggregates.\n",
      "\n",
      "But what happens when we have more than one table?\n",
      "Traditional relational databases usually contain many tables.\n",
      "Moreover, when integrating multiple data sets, we necessarily need tools to combine them.\n",
      "\n",
      "In this lab, we will use Panda's take on the database **join** operation to see how tables can be linked together.\n",
      "Specifically, we're going to perform a \"fuzzy join\" based on string edit-distance as another approach to finding duplicate records."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Setup\n",
      "\n",
      "### Data\n",
      "\n",
      "Today we'll be using a small data set of restaurants.\n",
      "Download the data from [here](https://raw.github.com/amplab/datascience-sp14/master/lab4/data/restaurants.csv).\n",
      "Put the data file, \"restaurants.csv\", in the same directory as this notebook.\n",
      "\n",
      "### Edit Distance\n",
      "\n",
      "We're going to be using a string-similarity python library to compute \"edit distance\".\n",
      "Install it on your VM by running the following:\n",
      "\n",
      "`sudo apt-get install python-levenshtein`\n",
      "\n",
      "**NOTE**: You may also need to run `sudo apt-get update`.\n",
      "\n",
      "To test that it works, the following should run OK:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Levenshtein as L"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Joins\n",
      "\n",
      "A **join** is a way to connect rows in two different data tables based on some criteria.\n",
      "Suppose the university has a database for student records with two tables in it: *Students* and *Grades*.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "Students = pd.DataFrame({'student_id': [1, 2], 'name': ['Alice', 'Bob']})\n",
      "Students"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>student_id</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Alice</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>   Bob</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "    name  student_id\n",
        "0  Alice           1\n",
        "1    Bob           2\n",
        "\n",
        "[2 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Grades = pd.DataFrame({'student_id': [1, 1, 2, 2], 'class_id': [1, 2, 1, 3], 'grade': ['A', 'C', 'B', 'B']})\n",
      "Grades"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>class_id</th>\n",
        "      <th>grade</th>\n",
        "      <th>student_id</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> A</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> C</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> B</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3</td>\n",
        "      <td> B</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>4 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "   class_id grade  student_id\n",
        "0         1     A           1\n",
        "1         2     C           1\n",
        "2         1     B           2\n",
        "3         3     B           2\n",
        "\n",
        "[4 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's say we want to know all of Bob's grades.\n",
      "Then, we can look up Bob's student ID in the Students table, and with the ID, look up his grades in the Grades table.\n",
      "Joins naturally express this process: when two tables share a common type of column (student ID in this case), we can join the tables together to get a complete view.\n",
      "\n",
      "In Pandas, we can use the **merge** method to perform a join.\n",
      "Pass the two tables to join as the first arguments, then the \"on\" parameter is set to the join column name."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.merge(Students, Grades, on='student_id')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>student_id</th>\n",
        "      <th>class_id</th>\n",
        "      <th>grade</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Alice</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> A</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Alice</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>   Bob</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> B</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>   Bob</td>\n",
        "      <td> 2</td>\n",
        "      <td> 3</td>\n",
        "      <td> B</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>4 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "    name  student_id  class_id grade\n",
        "0  Alice           1         1     A\n",
        "1  Alice           1         2     C\n",
        "2    Bob           2         1     B\n",
        "3    Bob           2         3     B\n",
        "\n",
        "[4 rows x 4 columns]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### DIY\n",
      "\n",
      "1. Use **merge** to join Grades with the Classes table below, and find out what class Alice got an A in."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Classes = pd.DataFrame({'class_id': [1, 2, 3], 'name': ['Math', 'English', 'Spanish']})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Joining the Restaurant Data\n",
      "\n",
      "Now let's load the restaurant data that we will be analyzing:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resto = pd.read_csv('restaurants.csv')\n",
      "resto.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "File restaurants.csv does not exist",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-7-e2c2852fbc7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'restaurants.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/bruckner/.virtualenvs/ipython/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     infer_datetime_format=infer_datetime_format)\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/bruckner/.virtualenvs/ipython/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/bruckner/.virtualenvs/ipython/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/bruckner/.virtualenvs/ipython/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/bruckner/.virtualenvs/ipython/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/bruckner/.virtualenvs/ipython/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:2965)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/bruckner/.virtualenvs/ipython/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:5304)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: File restaurants.csv does not exist"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resto[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The restaurant data has four columns.\n",
      "**id** is a unique ID field (unique for each row), **name** is the name of the restaurant, and **city** is where it is located.\n",
      "The fourth column, **cluster**, is a \"gold standard\" column.\n",
      "If two records have the same **cluster**, that means they are both about the same restaurant.\n",
      "\n",
      "The type of join we made above between Students and Grades, where we link records with equal values in a common column, is called an *equijoin*.\n",
      "Equijoins may join on more than one column, too (both value have to match).\n",
      "\n",
      "Let's use an equijoin to find pairs of duplicate restaurant records.\n",
      "We join the data to itself, on the **cluster** column.\n",
      "\n",
      "> Note: a join between a table and itself is called a *self-join*.\n",
      "\n",
      "The result (\"clusters\" below) has a lot of extra records in it.\n",
      "For example, since we're joining a table to itself, every record matches itself.\n",
      "We can filter on IDs to get rid of these extra join results.\n",
      "Note that when Pandas joins two tables that have columns with the same name, it appends \"_x\" and \"_y\" to the names to distinguish them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters = pd.merge(resto, resto, on='cluster')\n",
      "clusters = clusters[clusters.id_x != clusters.id_y]\n",
      "clusters[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### DIY\n",
      "\n",
      "1. There are still extra records in *clusters*, above.  If records *A* and *B* match each other, then we will get both (*A*, *B*) and (*B*, *A*) in the output.\n",
      "Filter *clusters* so that we only keep one instance of each matching pair (HINT: use the IDs again).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Fuzzy Joins\n",
      "\n",
      "Sometimes an equijoin isn't good enough.\n",
      "\n",
      "Say you want to match up records that are *almost* equal in a column.\n",
      "Or where a *function* of a columns is equal.\n",
      "Or maybe you don't care about equality: maybe \"less than\" or \"greater than or equal to\" is what you want.\n",
      "These cases call for a more general join than equijoin.\n",
      "\n",
      "We are going to make one of these joins between the restaurants data and itself.\n",
      "Specifically, we want to match up pairs of records whose restaurant names are *almost* the same.\n",
      "We call this a **fuzzy join**.\n",
      "\n",
      "To do a fuzzy join in Pandas we need to go about it in a few steps:\n",
      "\n",
      "1.  Join every record in the first table with every record in the second table. This is called the **Cartesian product** of the tables, and it's simply a list of all possible pairs of records.\n",
      "2.  Add a column to the Cartesian product that measures how \"similar\" each pair of records is. This is our **join criterion**.\n",
      "3.  Filter the Cartesian product based on when the join criterion is \"similar enough.\"\n",
      "\n",
      "> SQL Aside: In SQL, all of joins are supported in about the same way as equijoins are.\n",
      "> Essentially, you write a boolean expression on columns from the join-tables, and whenever that expression is true, you join the records together.\n",
      "> This is very similar to writing an **if** statement in python or Java.\n",
      "\n",
      "Let's do an example to get the hang of it."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 1. Join every record in the first table with every record in the second table.\n",
      "\n",
      "We use a \"dummy\" column to compute the Cartesian product of the data with itself.\n",
      "**dummy** takes the same value for every record, so we can do an equijoin and get back all pairs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resto['dummy'] = 0\n",
      "prod = pd.merge(resto, resto, on='dummy')\n",
      "\n",
      "# Clean up\n",
      "del prod['dummy']\n",
      "del resto['dummy']\n",
      "\n",
      "# Show that prod is the size of \"resto\" squared:\n",
      "print len(prod), len(resto)**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prod[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### DIY\n",
      "\n",
      "* Like we did with *clusters* remove \"extra\" record pairs, e.g., ones with the same ID."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2. Add a column to the Cartesian product that measures how \"similar\" each pair of records is.\n",
      "\n",
      "In the homework assignment, we used a string similarity metric called *cosine similarity* which measured how many \"tokens\" two strings shared in common.\n",
      "Now, we're going to use an alternative measure of string similarity  called *edit-distance*.\n",
      "[Edit-distance](http://en.wikipedia.org/wiki/Edit_distance) counts the number of simple changes you have to make to a string to turn it into another string.\n",
      "\n",
      "Import the edit distance library:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import Levenshtein as L\n",
      "\n",
      "L.distance('Hello, World!', 'Hallo, World!')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we add a computed column, named **distance**, that measures the edit distance between the names of two restaurants:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This takes a minute or two to run\n",
      "prod['distance'] = prod.apply(lambda r: L.distance(r['name_x'], r['name_y']), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.  Filter the Cartesian product based on when the join criterion is \"similar enough.\"\n",
      "\n",
      "Now we complete the join by filtering out pairs or records that aren't equal enough for our liking.\n",
      "As in the first homework assignment, we can only figure out how similar is \"similar enough\" by trying out some different options.\n",
      "Let's try maximum edit-distance from 0 to 10 and compute precision and recall."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pylab\n",
      "\n",
      "def accuracy(max_distance):\n",
      "    similar = prod[prod.distance < max_distance]\n",
      "    correct = float(sum(similar.cluster_x == similar.cluster_y))\n",
      "    precision = correct / len(similar)\n",
      "    recall = correct / len(clusters)\n",
      "    return (precision, recall)\n",
      "\n",
      "thresholds = range(1, 11)\n",
      "p = []\n",
      "r = []\n",
      "\n",
      "for t in thresholds:\n",
      "    acc = accuracy(t)\n",
      "    p.append(acc[0])\n",
      "    r.append(acc[1])\n",
      "\n",
      "pylab.plot(thresholds, p)\n",
      "pylab.plot(thresholds, r)\n",
      "pylab.legend(['precision', 'recall'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'prod' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-b161e99c7543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-1-b161e99c7543>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(max_distance)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msimilar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_x\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msimilar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'prod' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### DIY\n",
      "\n",
      "1. Another common way to visualize the tradeoff between precision and recall is to plot them directly against each other.\n",
      "Create a scatterplot with precision on one axis and recall on the other.\n",
      "Where are \"good\" points on the plot, and where are \"bad\" ones.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab.scatter(p, r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2. The python Levenshtein library provides another metric of string similarity called \"ratio\" (use `L.ratio(s1, s1)`).\n",
      "`ratio` gives a similarity score between 0 and 1, with higher meaning more similar.\n",
      "Add a column to \"prod\" with the `ratio` similarities of the **name** columns, and redo the precision/recall tradeoff analysis with the new metric.\n",
      "(Note: you will have to alter the `accuracy` method and the threshold range.)\n",
      "On this data, does `Levenshtein.ratio` do better than `Levenshtein.distance`?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}